{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d94baa62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import time\n",
    "import shutil\n",
    "from collections import OrderedDict\n",
    "from tqdm.auto import tqdm\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "plt.style.use('ggplot')\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('display.width', 1000)\n",
    "plt.rcParams['figure.figsize'] = (15, 5)\n",
    "plt.rcParams['axes.titlesize'] = 24\n",
    "plt.rcParams['axes.labelsize'] = 22\n",
    "plt.rcParams['ytick.labelsize'] = 20\n",
    "plt.rcParams['xtick.labelsize'] = 20\n",
    "\n",
    "# required to download pretrained model\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64bbeeed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Software\\envs\\env_1\\lib\\site-packages\\torchvision\\datasets\\mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "def load_model(pretrained):\n",
    "    class MLP(nn.Module):\n",
    "        def __init__(self, input_dims, n_hiddens, n_class, display=False):\n",
    "            super(MLP, self).__init__()\n",
    "            assert isinstance(input_dims, int), 'Please provide int for input_dims'\n",
    "            self.input_dims = input_dims\n",
    "            current_dims = input_dims\n",
    "            layers = OrderedDict()\n",
    "\n",
    "            if isinstance(n_hiddens, int):\n",
    "                n_hiddens = [n_hiddens]\n",
    "            else:\n",
    "                n_hiddens = list(n_hiddens)\n",
    "            for i, n_hidden in enumerate(n_hiddens):\n",
    "                layers['fc{}'.format(i+1)] = nn.Linear(current_dims, n_hidden)\n",
    "                layers['relu{}'.format(i+1)] = nn.ReLU()\n",
    "    #             layers['drop{}'.format(i+1)] = nn.Dropout(0.2)\n",
    "                current_dims = n_hidden\n",
    "            layers['out'] = nn.Linear(current_dims, n_class)\n",
    "\n",
    "            self.model= nn.Sequential(layers)\n",
    "            self.layers = layers\n",
    "            if display:\n",
    "                print(self.model)\n",
    "\n",
    "        def forward(self, input):\n",
    "            input = input.view(input.size(0), -1)\n",
    "            assert input.size(1) == self.input_dims\n",
    "            return self.model.forward(input)\n",
    "\n",
    "    def mnist(input_dims=784, n_hiddens=[256, 256], n_class=10, pretrained=False):\n",
    "        model_urls = {\n",
    "            'mnist': 'http://ml.cs.tsinghua.edu.cn/~chenxi/pytorch-models/mnist-b07bb66b.pth'\n",
    "        }\n",
    "        model = MLP(input_dims, n_hiddens, n_class)\n",
    "        m = model_zoo.load_url(model_urls['mnist'], map_location=torch.device('cpu'))\n",
    "        state_dict = m.state_dict() if isinstance(m, nn.Module) else m\n",
    "        model.load_state_dict(state_dict)\n",
    "        return model\n",
    "\n",
    "\n",
    "    def extract_W_B(pretrained):\n",
    "        model = mnist(input_dims=784, n_hiddens=[256, 256], n_class=10, pretrained=pretrained)\n",
    "        W = []\n",
    "        B = []\n",
    "        for i in range(3):\n",
    "            layer_name = f'fc{i+1}'\n",
    "            if i == 2:\n",
    "                layer_name = 'out'\n",
    "            layer = dict(model.layers)[layer_name]\n",
    "            W.append(layer.weight.detach().numpy())\n",
    "            B.append(layer.bias.detach().numpy())\n",
    "        return W, B\n",
    "\n",
    "    return extract_W_B(pretrained)\n",
    "\n",
    "def load_data():\n",
    "    mn = datasets.MNIST(root='tmp/public_dataset/pytorch/mnist-data', train=False, download=True)\n",
    "    x = list()\n",
    "    y = list()\n",
    "    for image, label in mn:\n",
    "        x.append(np.array(image))\n",
    "        y.append(label)\n",
    "    x = np.array(x) / 255\n",
    "    y = np.array(y)\n",
    "    return x, y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ace1cc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(v):\n",
    "    return np.maximum(0, v)\n",
    "\n",
    "def demo(pretrained):\n",
    "    W, B = load_model(pretrained)\n",
    "    \n",
    "    x, y = load_data()\n",
    "    x = (x - 0.1307) / 0.3081\n",
    "    x = x.reshape(-1, 28*28)\n",
    "    \n",
    "    x1 = x @ W[0].T + B[0]\n",
    "    y1 = relu(x1)\n",
    "\n",
    "    x2 = y1 @ W[1].T + B[1]\n",
    "    y2 = relu(x2)\n",
    "\n",
    "    x3 = y2 @ W[2].T + B[2]\n",
    "\n",
    "    return (x3.argmax(axis=1) == y).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1abaaf49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9842"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96ef2c4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9842"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo(pretrained=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
